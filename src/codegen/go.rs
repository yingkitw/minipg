//! Go code generator for minipg.
//!
//! Generates idiomatic Go parsers from grammar definitions.

use crate::ast::{Grammar, Rule};
use crate::core::{CodeGenerator, types::CodeGenConfig, Result};
use super::pattern_match::generate_simple_pattern_match;

/// Go code generator.
pub struct GoCodeGenerator;

impl GoCodeGenerator {
    pub fn new() -> Self {
        Self
    }
    
    fn generate_package_header(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str(&format!("// Package {} provides a parser generated by minipg.\n", grammar.name.to_lowercase()));
        code.push_str("//\n");
        code.push_str("// This code was automatically generated by minipg.\n");
        code.push_str("// DO NOT EDIT manually.\n");
        code.push_str(&format!("package {}\n\n", grammar.name.to_lowercase()));
        
        code.push_str("import (\n");
        code.push_str("\t\"fmt\"\n");
        code.push_str("\t\"strings\"\n");
        code.push_str(")\n\n");
        
        // Insert @header named action if present
        if let Some(header_code) = grammar.named_actions.get("header") {
            code.push_str("// Custom header from @header action\n");
            code.push_str(header_code);
            code.push_str("\n\n");
        }
        
        code
    }
    
    fn generate_token_types(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str("// TokenKind represents the type of a token.\n");
        code.push_str("type TokenKind int\n\n");
        code.push_str("const (\n");
        code.push_str("\tTokenEOF TokenKind = iota\n");
        
        // Add lexer rules as token types
        for rule in grammar.lexer_rules() {
            if !rule.is_fragment {
                code.push_str(&format!("\tToken{}\n", rule.name));
            }
        }
        
        code.push_str(")\n\n");
        
        // Generate String() method for TokenKind
        code.push_str("// String returns the string representation of the token kind.\n");
        code.push_str("func (k TokenKind) String() string {\n");
        code.push_str("\tswitch k {\n");
        code.push_str("\tcase TokenEOF:\n");
        code.push_str("\t\treturn \"EOF\"\n");
        
        for rule in grammar.lexer_rules() {
            if !rule.is_fragment {
                code.push_str(&format!("\tcase Token{}:\n", rule.name));
                code.push_str(&format!("\t\treturn \"{}\"\n", rule.name));
            }
        }
        
        code.push_str("\tdefault:\n");
        code.push_str("\t\treturn \"UNKNOWN\"\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_token_struct(&self) -> String {
        let mut code = String::new();
        
        code.push_str("// Token represents a lexical token.\n");
        code.push_str("type Token struct {\n");
        code.push_str("\tKind     TokenKind\n");
        code.push_str("\tText     string\n");
        code.push_str("\tPosition int\n");
        code.push_str("}\n\n");
        
        code.push_str("// String returns the string representation of the token.\n");
        code.push_str("func (t Token) String() string {\n");
        code.push_str("\treturn fmt.Sprintf(\"%s(%q)\", t.Kind, t.Text)\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_parse_error(&self) -> String {
        let mut code = String::new();
        
        code.push_str("// ParseError represents a parsing error.\n");
        code.push_str("type ParseError struct {\n");
        code.push_str("\tMessage  string\n");
        code.push_str("\tPosition int\n");
        code.push_str("\tExpected string\n");
        code.push_str("\tFound    string\n");
        code.push_str("}\n\n");
        
        code.push_str("// Error implements the error interface.\n");
        code.push_str("func (e *ParseError) Error() string {\n");
        code.push_str("\tif e.Expected != \"\" && e.Found != \"\" {\n");
        code.push_str("\t\treturn fmt.Sprintf(\"%s at position %d: expected %s, found %s\",\n");
        code.push_str("\t\t\te.Message, e.Position, e.Expected, e.Found)\n");
        code.push_str("\t}\n");
        code.push_str("\treturn fmt.Sprintf(\"%s at position %d\", e.Message, e.Position)\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_lexer(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str(&format!("// {}Lexer tokenizes input for the {} grammar.\n", grammar.name, grammar.name));
        code.push_str(&format!("type {}Lexer struct {{\n", grammar.name));
        code.push_str("\tinput    []rune\n");
        code.push_str("\tposition int\n");
        code.push_str("}\n\n");
        
        // New lexer constructor
        code.push_str(&format!("// New{}Lexer creates a new lexer from the input string.\n", grammar.name));
        code.push_str(&format!("func New{}Lexer(input string) *{}Lexer {{\n", grammar.name, grammar.name));
        code.push_str("\treturn &");
        code.push_str(&format!("{}Lexer{{\n", grammar.name));
        code.push_str("\t\tinput:    []rune(input),\n");
        code.push_str("\t\tposition: 0,\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        // NextToken method
        code.push_str("// NextToken returns the next token from the input.\n");
        code.push_str(&format!("func (l *{}Lexer) NextToken() (*Token, error) {{\n", grammar.name));
        code.push_str("\t// Skip whitespace\n");
        code.push_str("\tl.skipWhitespace()\n\n");
        code.push_str("\tstartPos := l.position\n\n");
        code.push_str("\t// Check for EOF\n");
        code.push_str("\tif l.position >= len(l.input) {\n");
        code.push_str("\t\treturn &Token{\n");
        code.push_str("\t\t\tKind:     TokenEOF,\n");
        code.push_str("\t\t\tText:     \"\",\n");
        code.push_str("\t\t\tPosition: startPos,\n");
        code.push_str("\t\t}, nil\n");
        code.push_str("\t}\n\n");
        code.push_str("\t// Try to match lexer rules in order\n");
        code.push_str("\t// Simple pattern matching (can be optimized with DFA later)\n");
        
        // Generate token matching logic for each lexer rule
        let lexer_rules: Vec<_> = grammar.lexer_rules()
            .filter(|r| !r.is_fragment)
            .collect();
        
        if !lexer_rules.is_empty() {
            code.push_str("\t// Try each lexer rule\n");
            for (i, rule) in lexer_rules.iter().enumerate() {
                if i == 0 {
                    code.push_str("\tif ");
                } else {
                    code.push_str("\t} else if ");
                }
                
                // Generate simple pattern matching
                // For now, generate a basic check - can be enhanced later
                code.push_str(&format!("l.match_{}() {{\n", rule.name.to_lowercase()));
                code.push_str("\t\t\ttext := l.input[startPos:l.position]\n");
                code.push_str(&format!("\t\t\treturn &Token{{\n"));
                code.push_str(&format!("\t\t\t\tKind:     Token{},\n", rule.name));
                code.push_str("\t\t\t\tText:     text,\n");
                code.push_str("\t\t\t\tPosition: startPos,\n");
                code.push_str("\t\t\t}, nil\n");
            }
            code.push_str("\t}\n\n");
        } else {
            code.push_str("\t// No lexer rules defined\n");
        }
        
        code.push_str("\t// Error recovery: skip invalid character\n");
        code.push_str("\tif l.position < len(l.input) {\n");
        code.push_str("\t\tinvalidChar := string(l.input[l.position])\n");
        code.push_str("\t\tl.position++\n");
        code.push_str("\t\treturn nil, &ParseError{\n");
        code.push_str("\t\t\tMessage:  fmt.Sprintf(\"Unexpected character: '%s'\", invalidChar),\n");
        code.push_str("\t\t\tPosition: startPos,\n");
        code.push_str("\t\t}\n");
        code.push_str("\t}\n");
        
        code.push_str("\treturn nil, &ParseError{\n");
        code.push_str("\t\tMessage:  \"Unexpected end of input\",\n");
        code.push_str("\t\tPosition: startPos,\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        // Generate match helper methods for each lexer rule (after NextToken method)
        let lexer_rules_for_helpers: Vec<_> = grammar.lexer_rules()
            .filter(|r| !r.is_fragment)
            .collect();
        
        if !lexer_rules_for_helpers.is_empty() {
            code.push_str("// Helper methods for pattern matching\n");
            for rule in lexer_rules_for_helpers {
                code.push_str(&generate_simple_pattern_match(rule, "go"));
                code.push_str("\n");
            }
        }
        
        // TokenizeAll method
        code.push_str("// TokenizeAll tokenizes all input and returns all tokens and errors.\n");
        code.push_str(&format!("func (l *{}Lexer) TokenizeAll() ([]*Token, []*ParseError) {{\n", grammar.name));
        code.push_str("\tvar tokens []*Token\n");
        code.push_str("\tvar errors []*ParseError\n\n");
        code.push_str("\tfor {\n");
        code.push_str("\t\ttoken, err := l.NextToken()\n");
        code.push_str("\t\tif err != nil {\n");
        code.push_str("\t\t\tif parseErr, ok := err.(*ParseError); ok {\n");
        code.push_str("\t\t\t\terrors = append(errors, parseErr)\n");
        code.push_str("\t\t\t}\n");
        code.push_str("\t\t\tif l.position >= len(l.input) {\n");
        code.push_str("\t\t\t\tbreak\n");
        code.push_str("\t\t\t}\n");
        code.push_str("\t\t\tcontinue\n");
        code.push_str("\t\t}\n");
        code.push_str("\t\ttokens = append(tokens, token)\n");
        code.push_str("\t\tif token.Kind == TokenEOF {\n");
        code.push_str("\t\t\tbreak\n");
        code.push_str("\t\t}\n");
        code.push_str("\t}\n\n");
        code.push_str("\treturn tokens, errors\n");
        code.push_str("}\n\n");
        
        // skipWhitespace helper
        code.push_str("// skipWhitespace skips whitespace characters.\n");
        code.push_str(&format!("func (l *{}Lexer) skipWhitespace() {{\n", grammar.name));
        code.push_str("\tfor l.position < len(l.input) {\n");
        code.push_str("\t\tswitch l.input[l.position] {\n");
        code.push_str("\t\tcase ' ', '\\t', '\\r', '\\n':\n");
        code.push_str("\t\t\tl.position++\n");
        code.push_str("\t\tdefault:\n");
        code.push_str("\t\t\treturn\n");
        code.push_str("\t\t}\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_parser(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str(&format!("// {}Parser parses input according to the {} grammar.\n", grammar.name, grammar.name));
        code.push_str(&format!("type {}Parser struct {{\n", grammar.name));
        code.push_str(&format!("\tlexer        *{}Lexer\n", grammar.name));
        code.push_str("\tcurrentToken *Token\n");
        
        // Insert @members named action if present
        if let Some(members_code) = grammar.named_actions.get("members") {
            code.push_str("\t// Custom members from @members action\n");
            code.push_str("\t");
            code.push_str(members_code);
            code.push_str("\n");
        }
        
        code.push_str("}\n\n");
        
        // New parser constructor
        code.push_str(&format!("// New{}Parser creates a new parser from the input string.\n", grammar.name));
        code.push_str(&format!("func New{}Parser(input string) *{}Parser {{\n", grammar.name, grammar.name));
        code.push_str(&format!("\tlexer := New{}Lexer(input)\n", grammar.name));
        code.push_str("\tp := &");
        code.push_str(&format!("{}Parser{{\n", grammar.name));
        code.push_str("\t\tlexer: lexer,\n");
        code.push_str("\t}\n");
        code.push_str("\t// Get first token\n");
        code.push_str("\tp.currentToken, _ = p.lexer.NextToken()\n");
        code.push_str("\treturn p\n");
        code.push_str("}\n\n");
        
        // Generate parser methods for each rule
        for rule in grammar.parser_rules() {
            code.push_str(&self.generate_parser_method(rule));
        }
        
        code
    }
    
    fn generate_parser_method(&self, rule: &Rule) -> String {
        let mut code = String::new();
        let method_name = capitalize(&rule.name);
        
        code.push_str(&format!("// Parse{} parses the {} rule.\n", method_name, rule.name));
        
        // Add parameter documentation
        if !rule.arguments.is_empty() {
            code.push_str("//\n");
            code.push_str("// Parameters:\n");
            for arg in &rule.arguments {
                let type_str = arg.arg_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}");
                code.push_str(&format!("//   {} - {} ({})\n", arg.name, type_str, "rule argument"));
            }
        }
        
        // Method signature
        code.push_str(&format!("func (p *{}Parser) Parse{}(", 
            rule.name.chars().next().unwrap().to_uppercase().collect::<String>() + &rule.name[1..],
            method_name));
        
        // Add arguments
        for (i, arg) in rule.arguments.iter().enumerate() {
            if i > 0 { code.push_str(", "); }
            code.push_str(&arg.name);
            code.push_str(" ");
            code.push_str(arg.arg_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}"));
        }
        
        code.push_str(") ");
        
        // Return type
        if rule.returns.is_empty() {
            code.push_str("error");
        } else if rule.returns.len() == 1 {
            let return_type = rule.returns[0].return_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}");
            code.push_str(&format!("({}, error)", return_type));
        } else {
            code.push_str("(");
            for (i, ret) in rule.returns.iter().enumerate() {
                if i > 0 { code.push_str(", "); }
                code.push_str(ret.return_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}"));
            }
            code.push_str(", error)");
        }
        
        code.push_str(" {\n");
        
        // Local variables
        for local in &rule.locals {
            let local_type = local.local_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}");
            code.push_str(&format!("\tvar {} {}\n", local.name, local_type));
        }
        if !rule.locals.is_empty() {
            code.push_str("\n");
        }
        
        // Generate parser logic for alternatives
        if rule.alternatives.len() > 1 {
            code.push_str("\t// Try each alternative\n");
            for (i, alt) in rule.alternatives.iter().enumerate() {
                if i == 0 {
                    code.push_str("\t// Try first alternative\n");
                } else {
                    code.push_str("\t// Try next alternative\n");
                }
                
                // Generate code for this alternative
                code.push_str(&self.generate_alternative_body(alt, rule));
                
                if i < rule.alternatives.len() - 1 {
                    code.push_str("\t// If failed, try next alternative\n");
                }
            }
            code.push_str("\t// All alternatives failed\n");
        } else if let Some(alt) = rule.alternatives.first() {
            code.push_str(&self.generate_alternative_body(alt, rule));
        } else {
            code.push_str("\t// Empty rule - always succeeds\n");
        }
        
        // Return statement
        if rule.returns.is_empty() {
            code.push_str("\treturn nil\n");
        } else if rule.returns.len() == 1 {
            let ret_name = &rule.returns[0].name;
            code.push_str(&format!("\treturn {}, nil\n", ret_name));
        } else {
            code.push_str("\treturn ");
            for (i, ret) in rule.returns.iter().enumerate() {
                if i > 0 { code.push_str(", "); }
                code.push_str(&ret.name);
            }
            code.push_str(", nil\n");
        }
        
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_alternative_body(&self, alt: &crate::ast::Alternative, rule: &Rule) -> String {
        let mut code = String::new();
        
        // Generate code for each element in sequence
        for element in &alt.elements {
            code.push_str(&self.generate_element_code(element, rule));
        }
        
        code
    }
    
    fn generate_element_code(&self, element: &crate::ast::Element, _rule: &Rule) -> String {
        let mut code = String::new();
        
        match element {
            crate::ast::Element::RuleRef { name, label, is_list } => {
                if *is_list {
                    if let Some(lbl) = label {
                        code.push_str(&format!("\tvar {} []interface{{}}\n", lbl));
                        code.push_str(&format!("\tfor {{\n"));
                        code.push_str(&format!("\t\tresult, err := p.Parse{}()\n", capitalize(name)));
                        code.push_str(&format!("\t\tif err != nil {{\n"));
                        code.push_str(&format!("\t\t\tbreak\n"));
                        code.push_str(&format!("\t\t}}\n"));
                        code.push_str(&format!("\t\t{} = append({}, result)\n", lbl, lbl));
                        code.push_str(&format!("\t}}\n"));
                    } else {
                        code.push_str(&format!("\tfor {{\n"));
                        code.push_str(&format!("\t\t_, err := p.Parse{}()\n", capitalize(name)));
                        code.push_str(&format!("\t\tif err != nil {{\n"));
                        code.push_str(&format!("\t\t\tbreak\n"));
                        code.push_str(&format!("\t\t}}\n"));
                        code.push_str(&format!("\t}}\n"));
                    }
                } else {
                    if let Some(lbl) = label {
                        code.push_str(&format!("\t{}, err := p.Parse{}()\n", lbl, capitalize(name)));
                        code.push_str(&format!("\tif err != nil {{\n"));
                        code.push_str(&format!("\t\treturn err\n"));
                        code.push_str(&format!("\t}}\n"));
                    } else {
                        code.push_str(&format!("\tif err := p.Parse{}(); err != nil {{\n", capitalize(name)));
                        code.push_str(&format!("\t\treturn err\n"));
                        code.push_str(&format!("\t}}\n"));
                    }
                }
            }
            crate::ast::Element::Terminal { value, label, is_list } => {
                if *is_list {
                    if let Some(lbl) = label {
                        code.push_str(&format!("\tvar {} []*Token\n", lbl));
                        code.push_str(&format!("\tfor p.currentToken != nil && p.currentToken.Kind == Token{} {{\n", value));
                        code.push_str(&format!("\t\t{} = append({}, p.currentToken)\n", lbl, lbl));
                        code.push_str(&format!("\t\tvar err error\n"));
                        code.push_str(&format!("\t\tp.currentToken, err = p.lexer.NextToken()\n"));
                        code.push_str(&format!("\t\tif err != nil {{\n"));
                        code.push_str(&format!("\t\t\tbreak\n"));
                        code.push_str(&format!("\t\t}}\n"));
                        code.push_str(&format!("\t}}\n"));
                    } else {
                        code.push_str(&format!("\tfor p.currentToken != nil && p.currentToken.Kind == Token{} {{\n", value));
                        code.push_str(&format!("\t\tvar err error\n"));
                        code.push_str(&format!("\t\tp.currentToken, err = p.lexer.NextToken()\n"));
                        code.push_str(&format!("\t\tif err != nil {{\n"));
                        code.push_str(&format!("\t\t\tbreak\n"));
                        code.push_str(&format!("\t\t}}\n"));
                        code.push_str(&format!("\t}}\n"));
                    }
                } else {
                    code.push_str(&format!("\tif p.currentToken == nil || p.currentToken.Kind != Token{} {{\n", value));
                    code.push_str(&format!("\t\treturn fmt.Errorf(\"expected token {}, got %%v\", p.currentToken)\n", value));
                    code.push_str(&format!("\t}}\n"));
                    if let Some(lbl) = label {
                        code.push_str(&format!("\t{} := p.currentToken\n", lbl));
                    }
                    code.push_str(&format!("\tvar err error\n"));
                    code.push_str(&format!("\tp.currentToken, err = p.lexer.NextToken()\n"));
                    code.push_str(&format!("\tif err != nil {{\n"));
                    code.push_str(&format!("\t\treturn err\n"));
                    code.push_str(&format!("\t}}\n"));
                }
            }
            _ => {
                code.push_str("\t// TODO: Handle other element types\n");
            }
        }
        
        code
    }
}

impl Default for GoCodeGenerator {
    fn default() -> Self {
        Self::new()
    }
}

impl CodeGenerator for GoCodeGenerator {
    type Input = Grammar;
    type Config = CodeGenConfig;
    
    fn target_language(&self) -> &str {
        "go"
    }
    
    fn generate(&self, grammar: &Grammar, _config: &CodeGenConfig) -> Result<String> {
        let mut code = String::new();
        
        // Package header and imports
        code.push_str(&self.generate_package_header(grammar));
        
        // Token types and structures
        code.push_str(&self.generate_token_types(grammar));
        code.push_str(&self.generate_token_struct());
        code.push_str(&self.generate_parse_error());
        
        // Lexer
        code.push_str(&self.generate_lexer(grammar));
        
        // Parser
        code.push_str(&self.generate_parser(grammar));
        
        Ok(code)
    }
}

fn capitalize(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::{Grammar, Rule, Element, Alternative};
    use crate::core::types::GrammarType;
    
    #[test]
    fn test_go_codegen_basic() {
        let grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        assert!(code.contains("package test"));
        assert!(code.contains("type TestLexer struct"));
        assert!(code.contains("type TestParser struct"));
        assert!(code.contains("type Token struct"));
        assert!(code.contains("type ParseError struct"));
    }

    #[test]
    fn test_go_codegen_with_rules() {
        use crate::ast::RuleType;
        let mut grammar = Grammar::new("Calculator".to_string(), GrammarType::Combined);
        
        // Add a parser rule
        let mut expr_rule = Rule::new("expr".to_string(), RuleType::Parser);
        let mut alt = Alternative::new();
        alt.add_element(Element::terminal("NUMBER".to_string()));
        expr_rule.alternatives.push(alt);
        grammar.rules.push(expr_rule);
        
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        assert!(code.contains("package calculator"));
        assert!(code.contains("type CalculatorLexer struct"));
        assert!(code.contains("type CalculatorParser struct"));
        // Parser methods are generated for parser rules
        assert!(code.contains("ParseExpr()"));
    }

    #[test]
    fn test_go_codegen_error_interface() {
        let grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        // Verify error interface implementation
        assert!(code.contains("func (e *ParseError) Error() string"));
        assert!(code.contains("type ParseError struct"));
        assert!(code.contains("Message  string"));
        assert!(code.contains("Position int"));
    }

    #[test]
    fn test_go_codegen_lexer_methods() {
        let grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        // Verify lexer methods
        assert!(code.contains("func NewTestLexer(input string)"));
        assert!(code.contains("func (l *TestLexer) NextToken()"));
        assert!(code.contains("func (l *TestLexer) TokenizeAll()"));
        assert!(code.contains("func (l *TestLexer) skipWhitespace()"));
    }

    #[test]
    fn test_go_codegen_parser_constructor() {
        let grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        // Verify parser constructor
        assert!(code.contains("func NewTestParser(input string)"));
        assert!(code.contains("lexer := NewTestLexer(input)"));
        assert!(code.contains("p.currentToken, _ = p.lexer.NextToken()"));
    }

    #[test]
    fn test_go_codegen_token_types() {
        use crate::ast::RuleType;
        let mut grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        
        // Add lexer rules
        let id_rule = Rule::new("ID".to_string(), RuleType::Lexer);
        let num_rule = Rule::new("NUMBER".to_string(), RuleType::Lexer);
        grammar.rules.push(id_rule);
        grammar.rules.push(num_rule);
        
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        // Verify token types
        assert!(code.contains("type TokenKind int"));
        assert!(code.contains("const ("));
        assert!(code.contains("TokenEOF TokenKind = iota"));
        assert!(code.contains("TokenID"));
        assert!(code.contains("TokenNUMBER"));
    }

    #[test]
    fn test_go_codegen_token_string_method() {
        use crate::ast::RuleType;
        let mut grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        
        // Add lexer rules
        let id_rule = Rule::new("ID".to_string(), RuleType::Lexer);
        grammar.rules.push(id_rule);
        
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        // Verify String() method for TokenKind
        assert!(code.contains("func (k TokenKind) String() string"));
        assert!(code.contains("case TokenEOF:"));
        assert!(code.contains("return \"EOF\""));
        assert!(code.contains("case TokenID:"));
        assert!(code.contains("return \"ID\""));
    }

    #[test]
    fn test_go_codegen_idiomatic_go() {
        let grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        // Verify idiomatic Go patterns
        // 1. Package declaration
        assert!(code.contains("package test"));
        
        // 2. Proper imports
        assert!(code.contains("import ("));
        assert!(code.contains("\"fmt\""));
        assert!(code.contains("\"strings\""));
        
        // 3. Exported types (PascalCase)
        assert!(code.contains("type TestLexer struct"));
        assert!(code.contains("type TestParser struct"));
        assert!(code.contains("type Token struct"));
        assert!(code.contains("type ParseError struct"));
        
        // 4. Error interface
        assert!(code.contains("func (e *ParseError) Error() string"));
        
        // 5. Receiver methods
        assert!(code.contains("func (l *TestLexer)"));
        assert!(code.contains("func (k TokenKind)"));
        
        // 6. Constructor functions
        assert!(code.contains("func NewTestLexer(input string)"));
        assert!(code.contains("func NewTestParser(input string)"));
    }

    #[test]
    fn test_go_codegen_target_language() {
        let code_gen = GoCodeGenerator::new();
        assert_eq!(code_gen.target_language(), "go");
    }

    #[test]
    fn test_go_codegen_default() {
        let code_gen = GoCodeGenerator::default();
        assert_eq!(code_gen.target_language(), "go");
    }
}
