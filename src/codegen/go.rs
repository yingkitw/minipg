//! Go code generator for minipg.
//!
//! Generates idiomatic Go parsers from grammar definitions.

use crate::ast::{Grammar, Rule};
use crate::core::{CodeGenerator, types::CodeGenConfig, Result};

/// Go code generator.
pub struct GoCodeGenerator;

impl GoCodeGenerator {
    pub fn new() -> Self {
        Self
    }
    
    fn generate_package_header(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str(&format!("// Package {} provides a parser generated by minipg.\n", grammar.name.to_lowercase()));
        code.push_str("//\n");
        code.push_str("// This code was automatically generated by minipg.\n");
        code.push_str("// DO NOT EDIT manually.\n");
        code.push_str(&format!("package {}\n\n", grammar.name.to_lowercase()));
        
        code.push_str("import (\n");
        code.push_str("\t\"fmt\"\n");
        code.push_str("\t\"strings\"\n");
        code.push_str(")\n\n");
        
        // Insert @header named action if present
        if let Some(header_code) = grammar.named_actions.get("header") {
            code.push_str("// Custom header from @header action\n");
            code.push_str(header_code);
            code.push_str("\n\n");
        }
        
        code
    }
    
    fn generate_token_types(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str("// TokenKind represents the type of a token.\n");
        code.push_str("type TokenKind int\n\n");
        code.push_str("const (\n");
        code.push_str("\tTokenEOF TokenKind = iota\n");
        
        // Add lexer rules as token types
        for rule in grammar.lexer_rules() {
            if !rule.is_fragment {
                code.push_str(&format!("\tToken{}\n", rule.name));
            }
        }
        
        code.push_str(")\n\n");
        
        // Generate String() method for TokenKind
        code.push_str("// String returns the string representation of the token kind.\n");
        code.push_str("func (k TokenKind) String() string {\n");
        code.push_str("\tswitch k {\n");
        code.push_str("\tcase TokenEOF:\n");
        code.push_str("\t\treturn \"EOF\"\n");
        
        for rule in grammar.lexer_rules() {
            if !rule.is_fragment {
                code.push_str(&format!("\tcase Token{}:\n", rule.name));
                code.push_str(&format!("\t\treturn \"{}\"\n", rule.name));
            }
        }
        
        code.push_str("\tdefault:\n");
        code.push_str("\t\treturn \"UNKNOWN\"\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_token_struct(&self) -> String {
        let mut code = String::new();
        
        code.push_str("// Token represents a lexical token.\n");
        code.push_str("type Token struct {\n");
        code.push_str("\tKind     TokenKind\n");
        code.push_str("\tText     string\n");
        code.push_str("\tPosition int\n");
        code.push_str("}\n\n");
        
        code.push_str("// String returns the string representation of the token.\n");
        code.push_str("func (t Token) String() string {\n");
        code.push_str("\treturn fmt.Sprintf(\"%s(%q)\", t.Kind, t.Text)\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_parse_error(&self) -> String {
        let mut code = String::new();
        
        code.push_str("// ParseError represents a parsing error.\n");
        code.push_str("type ParseError struct {\n");
        code.push_str("\tMessage  string\n");
        code.push_str("\tPosition int\n");
        code.push_str("\tExpected string\n");
        code.push_str("\tFound    string\n");
        code.push_str("}\n\n");
        
        code.push_str("// Error implements the error interface.\n");
        code.push_str("func (e *ParseError) Error() string {\n");
        code.push_str("\tif e.Expected != \"\" && e.Found != \"\" {\n");
        code.push_str("\t\treturn fmt.Sprintf(\"%s at position %d: expected %s, found %s\",\n");
        code.push_str("\t\t\te.Message, e.Position, e.Expected, e.Found)\n");
        code.push_str("\t}\n");
        code.push_str("\treturn fmt.Sprintf(\"%s at position %d\", e.Message, e.Position)\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_lexer(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str(&format!("// {}Lexer tokenizes input for the {} grammar.\n", grammar.name, grammar.name));
        code.push_str(&format!("type {}Lexer struct {{\n", grammar.name));
        code.push_str("\tinput    []rune\n");
        code.push_str("\tposition int\n");
        code.push_str("}\n\n");
        
        // New lexer constructor
        code.push_str(&format!("// New{}Lexer creates a new lexer from the input string.\n", grammar.name));
        code.push_str(&format!("func New{}Lexer(input string) *{}Lexer {{\n", grammar.name, grammar.name));
        code.push_str("\treturn &");
        code.push_str(&format!("{}Lexer{{\n", grammar.name));
        code.push_str("\t\tinput:    []rune(input),\n");
        code.push_str("\t\tposition: 0,\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        // NextToken method
        code.push_str("// NextToken returns the next token from the input.\n");
        code.push_str(&format!("func (l *{}Lexer) NextToken() (*Token, error) {{\n", grammar.name));
        code.push_str("\t// Skip whitespace\n");
        code.push_str("\tl.skipWhitespace()\n\n");
        code.push_str("\tstartPos := l.position\n\n");
        code.push_str("\t// Check for EOF\n");
        code.push_str("\tif l.position >= len(l.input) {\n");
        code.push_str("\t\treturn &Token{\n");
        code.push_str("\t\t\tKind:     TokenEOF,\n");
        code.push_str("\t\t\tText:     \"\",\n");
        code.push_str("\t\t\tPosition: startPos,\n");
        code.push_str("\t\t}, nil\n");
        code.push_str("\t}\n\n");
        code.push_str("\t// TODO: Implement tokenization logic\n");
        code.push_str("\treturn nil, &ParseError{\n");
        code.push_str("\t\tMessage:  \"Tokenization not yet implemented\",\n");
        code.push_str("\t\tPosition: startPos,\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        // TokenizeAll method
        code.push_str("// TokenizeAll tokenizes all input and returns all tokens and errors.\n");
        code.push_str(&format!("func (l *{}Lexer) TokenizeAll() ([]*Token, []*ParseError) {{\n", grammar.name));
        code.push_str("\tvar tokens []*Token\n");
        code.push_str("\tvar errors []*ParseError\n\n");
        code.push_str("\tfor {\n");
        code.push_str("\t\ttoken, err := l.NextToken()\n");
        code.push_str("\t\tif err != nil {\n");
        code.push_str("\t\t\tif parseErr, ok := err.(*ParseError); ok {\n");
        code.push_str("\t\t\t\terrors = append(errors, parseErr)\n");
        code.push_str("\t\t\t}\n");
        code.push_str("\t\t\tif l.position >= len(l.input) {\n");
        code.push_str("\t\t\t\tbreak\n");
        code.push_str("\t\t\t}\n");
        code.push_str("\t\t\tcontinue\n");
        code.push_str("\t\t}\n");
        code.push_str("\t\ttokens = append(tokens, token)\n");
        code.push_str("\t\tif token.Kind == TokenEOF {\n");
        code.push_str("\t\t\tbreak\n");
        code.push_str("\t\t}\n");
        code.push_str("\t}\n\n");
        code.push_str("\treturn tokens, errors\n");
        code.push_str("}\n\n");
        
        // skipWhitespace helper
        code.push_str("// skipWhitespace skips whitespace characters.\n");
        code.push_str(&format!("func (l *{}Lexer) skipWhitespace() {{\n", grammar.name));
        code.push_str("\tfor l.position < len(l.input) {\n");
        code.push_str("\t\tswitch l.input[l.position] {\n");
        code.push_str("\t\tcase ' ', '\\t', '\\r', '\\n':\n");
        code.push_str("\t\t\tl.position++\n");
        code.push_str("\t\tdefault:\n");
        code.push_str("\t\t\treturn\n");
        code.push_str("\t\t}\n");
        code.push_str("\t}\n");
        code.push_str("}\n\n");
        
        code
    }
    
    fn generate_parser(&self, grammar: &Grammar) -> String {
        let mut code = String::new();
        
        code.push_str(&format!("// {}Parser parses input according to the {} grammar.\n", grammar.name, grammar.name));
        code.push_str(&format!("type {}Parser struct {{\n", grammar.name));
        code.push_str(&format!("\tlexer        *{}Lexer\n", grammar.name));
        code.push_str("\tcurrentToken *Token\n");
        
        // Insert @members named action if present
        if let Some(members_code) = grammar.named_actions.get("members") {
            code.push_str("\t// Custom members from @members action\n");
            code.push_str("\t");
            code.push_str(members_code);
            code.push_str("\n");
        }
        
        code.push_str("}\n\n");
        
        // New parser constructor
        code.push_str(&format!("// New{}Parser creates a new parser from the input string.\n", grammar.name));
        code.push_str(&format!("func New{}Parser(input string) *{}Parser {{\n", grammar.name, grammar.name));
        code.push_str(&format!("\tlexer := New{}Lexer(input)\n", grammar.name));
        code.push_str("\tp := &");
        code.push_str(&format!("{}Parser{{\n", grammar.name));
        code.push_str("\t\tlexer: lexer,\n");
        code.push_str("\t}\n");
        code.push_str("\t// Get first token\n");
        code.push_str("\tp.currentToken, _ = p.lexer.NextToken()\n");
        code.push_str("\treturn p\n");
        code.push_str("}\n\n");
        
        // Generate parser methods for each rule
        for rule in grammar.parser_rules() {
            code.push_str(&self.generate_parser_method(rule));
        }
        
        code
    }
    
    fn generate_parser_method(&self, rule: &Rule) -> String {
        let mut code = String::new();
        let method_name = capitalize(&rule.name);
        
        code.push_str(&format!("// Parse{} parses the {} rule.\n", method_name, rule.name));
        
        // Add parameter documentation
        if !rule.arguments.is_empty() {
            code.push_str("//\n");
            code.push_str("// Parameters:\n");
            for arg in &rule.arguments {
                let type_str = arg.arg_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}");
                code.push_str(&format!("//   {} - {} ({})\n", arg.name, type_str, "rule argument"));
            }
        }
        
        // Method signature
        code.push_str(&format!("func (p *{}Parser) Parse{}(", 
            rule.name.chars().next().unwrap().to_uppercase().collect::<String>() + &rule.name[1..],
            method_name));
        
        // Add arguments
        for (i, arg) in rule.arguments.iter().enumerate() {
            if i > 0 { code.push_str(", "); }
            code.push_str(&arg.name);
            code.push_str(" ");
            code.push_str(arg.arg_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}"));
        }
        
        code.push_str(") ");
        
        // Return type
        if rule.returns.is_empty() {
            code.push_str("error");
        } else if rule.returns.len() == 1 {
            let return_type = rule.returns[0].return_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}");
            code.push_str(&format!("({}, error)", return_type));
        } else {
            code.push_str("(");
            for (i, ret) in rule.returns.iter().enumerate() {
                if i > 0 { code.push_str(", "); }
                code.push_str(ret.return_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}"));
            }
            code.push_str(", error)");
        }
        
        code.push_str(" {\n");
        
        // Local variables
        for local in &rule.locals {
            let local_type = local.local_type.as_ref().map(|t| t.as_str()).unwrap_or("interface{}");
            code.push_str(&format!("\tvar {} {}\n", local.name, local_type));
        }
        if !rule.locals.is_empty() {
            code.push_str("\n");
        }
        
        code.push_str("\t// TODO: Implement parser logic\n");
        
        if rule.returns.is_empty() {
            code.push_str("\treturn nil\n");
        } else if rule.returns.len() == 1 {
            code.push_str("\treturn nil, nil\n");
        } else {
            code.push_str("\treturn ");
            for (i, _) in rule.returns.iter().enumerate() {
                if i > 0 { code.push_str(", "); }
                code.push_str("nil");
            }
            code.push_str(", nil\n");
        }
        
        code.push_str("}\n\n");
        
        code
    }
}

impl Default for GoCodeGenerator {
    fn default() -> Self {
        Self::new()
    }
}

impl CodeGenerator for GoCodeGenerator {
    type Input = Grammar;
    type Config = CodeGenConfig;
    
    fn target_language(&self) -> &str {
        "go"
    }
    
    fn generate(&self, grammar: &Grammar, _config: &CodeGenConfig) -> Result<String> {
        let mut code = String::new();
        
        // Package header and imports
        code.push_str(&self.generate_package_header(grammar));
        
        // Token types and structures
        code.push_str(&self.generate_token_types(grammar));
        code.push_str(&self.generate_token_struct());
        code.push_str(&self.generate_parse_error());
        
        // Lexer
        code.push_str(&self.generate_lexer(grammar));
        
        // Parser
        code.push_str(&self.generate_parser(grammar));
        
        Ok(code)
    }
}

fn capitalize(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::Grammar;
    use crate::core::types::GrammarType;
    
    #[test]
    fn test_go_codegen_basic() {
        let grammar = Grammar::new("Test".to_string(), GrammarType::Combined);
        let code_gen = GoCodeGenerator::new();
        let config = CodeGenConfig::default();
        
        let code = code_gen.generate(&grammar, &config).expect("Failed to generate");
        
        assert!(code.contains("package test"));
        assert!(code.contains("type TestLexer struct"));
        assert!(code.contains("type TestParser struct"));
        assert!(code.contains("type Token struct"));
        assert!(code.contains("type ParseError struct"));
    }
}
